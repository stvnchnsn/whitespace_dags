[2023-06-27T03:23:12.081+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: search_posts.update_db manual__2023-06-27T03:20:38.377999+00:00 [queued]>
[2023-06-27T03:23:12.102+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: search_posts.update_db manual__2023-06-27T03:20:38.377999+00:00 [queued]>
[2023-06-27T03:23:12.104+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-27T03:23:12.133+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonOperator): update_db> on 2023-06-27 03:20:38.377999+00:00
[2023-06-27T03:23:12.146+0000] {standard_task_runner.py:57} INFO - Started process 2048 to run task
[2023-06-27T03:23:12.159+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'search_posts', 'update_db', 'manual__2023-06-27T03:20:38.377999+00:00', '--job-id', '106', '--raw', '--subdir', 'DAGS_FOLDER/search_posts.py', '--cfg-path', '/tmp/tmps1ewj9e2']
[2023-06-27T03:23:12.164+0000] {standard_task_runner.py:85} INFO - Job 106: Subtask update_db
[2023-06-27T03:23:12.308+0000] {task_command.py:410} INFO - Running <TaskInstance: search_posts.update_db manual__2023-06-27T03:20:38.377999+00:00 [running]> on host 414be138234a
[2023-06-27T03:23:12.671+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='search_posts' AIRFLOW_CTX_TASK_ID='update_db' AIRFLOW_CTX_EXECUTION_DATE='2023-06-27T03:20:38.377999+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-27T03:20:38.377999+00:00'
[2023-06-27T03:23:12.972+0000] {logging_mixin.py:149} INFO - 
    fresh_data.shape: (4155, 16)
    old_data.shape: (4056, 1)
    update_data.shape: (3088, 16)
    
[2023-06-27T03:23:13.008+0000] {logging_mixin.py:149} INFO -                     created   created_utc  ... search_term                topic
0 2023-06-06 10:58:50-05:00  1.686067e+09  ...     alcohol  alcoholic_beverages
1 2023-06-14 11:27:31-05:00  1.686760e+09  ...     alcohol  alcoholic_beverages
2 2023-05-23 09:16:55-05:00  1.684851e+09  ...     alcohol  alcoholic_beverages
3 2023-06-24 19:20:46-05:00  1.687652e+09  ...     alcohol  alcoholic_beverages
4 2023-06-17 18:15:42-05:00  1.687044e+09  ...     alcohol  alcoholic_beverages

[5 rows x 16 columns]
[2023-06-27T03:23:13.078+0000] {logging_mixin.py:149} INFO - INSERT INTO reddit_db.raw_reddit_pulls (id, created, subreddit, subreddit_id, selftext, author_fullname, title, name, url) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
[2023-06-27T03:23:13.430+0000] {taskinstance.py:1824} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 181, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 198, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/search_posts.py", line 69, in update_db
    update_bq_from_df(update_data[cols], table_name)
  File "/opt/airflow/dags/lib/big_query_access.py", line 29, in update_bq_from_df
    client.query(sql_statement)
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 3416, in query
    job_retry,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/bigquery/_job_helpers.py", line 114, in query_jobs_insert
    future = do_query()
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/bigquery/_job_helpers.py", line 91, in do_query
    query_job._begin(retry=retry, timeout=timeout)
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/bigquery/job/query.py", line 1310, in _begin
    super(QueryJob, self)._begin(client=client, retry=retry, timeout=timeout)
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/bigquery/job/base.py", line 701, in _begin
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 814, in _call_api
    return call()
  File "/home/airflow/.local/lib/python3.7/site-packages/google/api_core/retry.py", line 354, in retry_wrapped_func
    on_error=on_error,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/api_core/retry.py", line 191, in retry_target
    return target()
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/_http/__init__.py", line 494, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/bigquery/v2/projects/reddit_db.raw_reddit_pulls/jobs?prettyPrint=false: ProjectId and DatasetId must be non-empty

Location: None
Job ID: 7bb743a3-9bd1-4995-a240-dd4f54a4427f

[2023-06-27T03:23:13.486+0000] {taskinstance.py:1350} INFO - Marking task as FAILED. dag_id=search_posts, task_id=update_db, execution_date=20230627T032038, start_date=20230627T032312, end_date=20230627T032313
[2023-06-27T03:23:13.516+0000] {standard_task_runner.py:109} ERROR - Failed to execute job 106 for task update_db (400 POST https://bigquery.googleapis.com/bigquery/v2/projects/reddit_db.raw_reddit_pulls/jobs?prettyPrint=false: ProjectId and DatasetId must be non-empty

Location: None
Job ID: 7bb743a3-9bd1-4995-a240-dd4f54a4427f
; 2048)
[2023-06-27T03:23:13.595+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 1
[2023-06-27T03:23:13.645+0000] {taskinstance.py:2653} INFO - 0 downstream tasks scheduled from follow-on schedule check
